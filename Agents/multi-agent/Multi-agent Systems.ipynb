{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPXctV/DvXbnncnHafdPich"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Multi-Agent Systems"],"metadata":{"id":"rq37GvOD9mBW"}},{"cell_type":"markdown","source":["In multi-agent architectures, agents can be represented as graph nodes.\n","\n","Each agent node executes its step(s) and decides whether to finish execution or route to another agent, including potentially routing to itself (e.g., running in a loop).\n","\n","A common pattern in multi-agent interactions is handoffs, where one agent hands off control to another.\n","\n","Handoffs allow you to specify:\n","\n","- destination: target agent to navigate to (e.g., name of the node to go to)\n","- payload: information to pass to that agent (e.g., state update)\n","To implement handoffs in LangGraph, agent nodes can return Command object that allows you to combine both control flow and state updates:"],"metadata":{"id":"NQDD6eEK9vZR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZHSHiA_j9cxL"},"outputs":[],"source":["def agent(state) -> Command[Literal[\"agent\", \"another_agent\"]]:\n","    # the condition for routing/halting can be anything, e.g. LLM tool call / structured output, etc.\n","    goto = get_next_agent(...)  # 'agent' / 'another_agent'\n","    return Command(\n","        # Specify which agent to call next\n","        goto=goto,\n","        # Update the graph state\n","        update={\"my_state_key\": \"my_state_value\"}\n","    )"]},{"cell_type":"markdown","source":["In a more complex scenario where each agent node is itself a graph (i.e., a subgraph), a node in one of the agent subgraphs might want to navigate to a different agent.\n","\n","For example, if you have two agents, alice and bob (subgraph nodes in a parent graph), and alice needs to navigate to bob, you can set graph=Command.PARENT in the Command object:\n","\n"],"metadata":{"id":"vLeZyI1F98pr"}},{"cell_type":"code","source":["def some_node_inside_alice(state)\n","    return Command(\n","        goto=\"bob\",\n","        update={\"my_state_key\": \"my_state_value\"},\n","        # specify which graph to navigate to (defaults to the current graph)\n","        graph=Command.PARENT,\n","    )"],"metadata":{"id":"SrhXF1iH-Bkv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Network"],"metadata":{"id":"D_VCMGFO-tFf"}},{"cell_type":"markdown","source":["In this architecture, agents are defined as graph nodes.\n","\n","Each agent can communicate with every other agent (many-to-many connections) and can decide which agent to call next.\n","\n","This architecture is good for problems that do not have a clear hierarchy of agents or a specific sequence in which agents should be called.\n","\n"],"metadata":{"id":"vQ1QOj-2-xIA"}},{"cell_type":"code","source":["from typing import Literal\n","from langchain_openai import ChatOpenAI\n","from langgraph.types import Command\n","from langgraph.graph import StateGraph, MessagesState, START, END\n","\n","model = ChatOpenAI()\n","\n","def agent_1(state: MessagesState) -> Command[Literal[\"agent_2\", \"agent_3\", END]]:\n","    # you can pass relevant parts of the state to the LLM (e.g., state[\"messages\"])\n","    # to determine which agent to call next. a common pattern is to call the model\n","    # with a structured output (e.g. force it to return an output with a \"next_agent\" field)\n","    response = model.invoke(...)\n","    # route to one of the agents or exit based on the LLM's decision\n","    # if the LLM returns \"__end__\", the graph will finish execution\n","    return Command(\n","        goto=response[\"next_agent\"],\n","        update={\"messages\": [response[\"content\"]]},\n","    )\n","\n","def agent_2(state: MessagesState) -> Command[Literal[\"agent_1\", \"agent_3\", END]]:\n","    response = model.invoke(...)\n","    return Command(\n","        goto=response[\"next_agent\"],\n","        update={\"messages\": [response[\"content\"]]},\n","    )\n","\n","def agent_3(state: MessagesState) -> Command[Literal[\"agent_1\", \"agent_2\", END]]:\n","    ...\n","    return Command(\n","        goto=response[\"next_agent\"],\n","        update={\"messages\": [response[\"content\"]]},\n","    )\n","\n","builder = StateGraph(MessagesState)\n","builder.add_node(agent_1)\n","builder.add_node(agent_2)\n","builder.add_node(agent_3)\n","\n","builder.add_edge(START, \"agent_1\")\n","network = builder.compile()"],"metadata":{"id":"GwZuU1Co-zSB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Supervisor\n","\n","\n"],"metadata":{"id":"s089L12c_OIg"}},{"cell_type":"markdown","source":["In this architecture, we define agents as nodes and add a supervisor node (LLM) that decides which agent nodes should be called next.\n","\n","We use Command to route execution to the appropriate agent node based on supervisor's decision. This architecture also lends itself well to running multiple agents in parallel or using map-reduce pattern.\n","\n"],"metadata":{"id":"4URleJsk_Tju"}},{"cell_type":"code","source":["from typing import Literal\n","from langchain_openai import ChatOpenAI\n","from langgraph.types import Command\n","from langgraph.graph import StateGraph, MessagesState, START, END\n","\n","model = ChatOpenAI()\n","\n","def supervisor(state: MessagesState) -> Command[Literal[\"agent_1\", \"agent_2\", END]]:\n","    # you can pass relevant parts of the state to the LLM (e.g., state[\"messages\"])\n","    # to determine which agent to call next. a common pattern is to call the model\n","    # with a structured output (e.g. force it to return an output with a \"next_agent\" field)\n","    response = model.invoke(...)\n","    # route to one of the agents or exit based on the supervisor's decision\n","    # if the supervisor returns \"__end__\", the graph will finish execution\n","    return Command(goto=response[\"next_agent\"])\n","\n","def agent_1(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n","    # you can pass relevant parts of the state to the LLM (e.g., state[\"messages\"])\n","    # and add any additional logic (different models, custom prompts, structured output, etc.)\n","    response = model.invoke(...)\n","    return Command(\n","        goto=\"supervisor\",\n","        update={\"messages\": [response]},\n","    )\n","\n","def agent_2(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n","    response = model.invoke(...)\n","    return Command(\n","        goto=\"supervisor\",\n","        update={\"messages\": [response]},\n","    )\n","\n","builder = StateGraph(MessagesState)\n","builder.add_node(supervisor)\n","builder.add_node(agent_1)\n","builder.add_node(agent_2)\n","\n","builder.add_edge(START, \"supervisor\")\n","\n","supervisor = builder.compile()"],"metadata":{"id":"WKuoArBf_WFX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hierarchical"],"metadata":{"id":"wEeRBRzhAcBQ"}},{"cell_type":"markdown","source":["As you add more agents to your system, it might become too hard for the supervisor to manage all of them.\n","\n","The supervisor might start making poor decisions about which agent to call next, the context might become too complex for a single supervisor to keep track of.\n","\n","In other words, you end up with the same problems that motivated the multi-agent architecture in the first place.\n","\n"],"metadata":{"id":"ib33KcUYAjN7"}},{"cell_type":"markdown","source":["To address this, you can design your system hierarchically. For example, you can create separate, specialized teams of agents managed by individual supervisors, and a top-level supervisor to manage the teams.\n","\n"],"metadata":{"id":"PgxUeTgTAmbT"}},{"cell_type":"code","source":["from typing import Literal\n","from langchain_openai import ChatOpenAI\n","from langgraph.graph import StateGraph, MessagesState, START, END\n","from langgraph.types import Command\n","model = ChatOpenAI()\n","\n","# define team 1 (same as the single supervisor example above)\n","\n","def team_1_supervisor(state: MessagesState) -> Command[Literal[\"team_1_agent_1\", \"team_1_agent_2\", END]]:\n","    response = model.invoke(...)\n","    return Command(goto=response[\"next_agent\"])\n","\n","def team_1_agent_1(state: MessagesState) -> Command[Literal[\"team_1_supervisor\"]]:\n","    response = model.invoke(...)\n","    return Command(goto=\"team_1_supervisor\", update={\"messages\": [response]})\n","\n","def team_1_agent_2(state: MessagesState) -> Command[Literal[\"team_1_supervisor\"]]:\n","    response = model.invoke(...)\n","    return Command(goto=\"team_1_supervisor\", update={\"messages\": [response]})\n","\n","team_1_builder = StateGraph(Team1State)\n","team_1_builder.add_node(team_1_supervisor)\n","team_1_builder.add_node(team_1_agent_1)\n","team_1_builder.add_node(team_1_agent_2)\n","team_1_builder.add_edge(START, \"team_1_supervisor\")\n","\n","team_1_graph = team_1_builder.compile()\n","\n","# define team 2 (same as the single supervisor example above)\n","class Team2State(MessagesState):\n","    next: Literal[\"team_2_agent_1\", \"team_2_agent_2\", \"__end__\"]\n","\n","def team_2_supervisor(state: Team2State):\n","    ...\n","\n","def team_2_agent_1(state: Team2State):\n","    ...\n","\n","def team_2_agent_2(state: Team2State):\n","    ...\n","\n","team_2_builder = StateGraph(Team2State)\n","...\n","team_2_graph = team_2_builder.compile()\n","\n","\n","# define top-level supervisor\n","\n","builder = StateGraph(MessagesState)\n","def top_level_supervisor(state: MessagesState) -> Command[Literal[\"team_1_graph\", \"team_2_graph\", END]]:\n","    # you can pass relevant parts of the state to the LLM (e.g., state[\"messages\"])\n","    # to determine which team to call next. a common pattern is to call the model\n","    # with a structured output (e.g. force it to return an output with a \"next_team\" field)\n","    response = model.invoke(...)\n","    # route to one of the teams or exit based on the supervisor's decision\n","    # if the supervisor returns \"__end__\", the graph will finish execution\n","    return Command(goto=response[\"next_team\"])\n","\n","builder = StateGraph(MessagesState)\n","builder.add_node(top_level_supervisor)\n","builder.add_node(\"team_1_graph\", team_1_graph)\n","builder.add_node(\"team_2_graph\", team_2_graph)\n","builder.add_edge(START, \"top_level_supervisor\")\n","builder.add_edge(\"team_1_graph\", \"top_level_supervisor\")\n","builder.add_edge(\"team_2_graph\", \"top_level_supervisor\")\n","graph = builder.compile()"],"metadata":{"id":"kCTgZXr-A3FN"},"execution_count":null,"outputs":[]}]}