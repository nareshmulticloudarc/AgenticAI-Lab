{"cells":[{"cell_type":"markdown","id":"df62afaf-4235-431d-94b3-664e14386422","metadata":{"id":"df62afaf-4235-431d-94b3-664e14386422"},"source":["# Runnable Functions"]},{"cell_type":"markdown","id":"28013522","metadata":{"id":"28013522"},"source":["In this notebook you will learn how to convert custom functions into runnables that can be included in LangChain chains."]},{"cell_type":"markdown","id":"69366671-11a4-4439-b6ad-cb89497ef5d4","metadata":{"id":"69366671-11a4-4439-b6ad-cb89497ef5d4"},"source":["---"]},{"cell_type":"markdown","id":"c08054f2","metadata":{"id":"c08054f2"},"source":["## Objectives"]},{"cell_type":"markdown","id":"a023bc7a-47b5-4508-957c-f3354c9fb363","metadata":{"id":"a023bc7a-47b5-4508-957c-f3354c9fb363"},"source":["By the time you complete this notebook you will:\n","\n","- Understand how to create custom runnable functions and include them in your LangChain chains.\n","- Use custom runnable functions to preprocess data before sending it to an LLM.\n","- Use custom functions to batch translate raw text into prompt templates.\n","- Create a LangChain sentiment analysis chain utilizing multiple custom runnable functions."]},{"cell_type":"markdown","id":"f4e9ea06-814f-43fd-9f59-ce67dfcb1bbb","metadata":{"id":"f4e9ea06-814f-43fd-9f59-ce67dfcb1bbb"},"source":["---"]},{"cell_type":"code","source":["!pip install groq langchain-groq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_UJ4RepTPxF9","executionInfo":{"status":"ok","timestamp":1757425082551,"user_tz":0,"elapsed":10075,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"2fa51e0c-54fc-43b5-eb43-ba7e2736eb66"},"id":"_UJ4RepTPxF9","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting groq\n","  Downloading groq-0.31.1-py3-none-any.whl.metadata (16 kB)\n","Collecting langchain-groq\n","  Downloading langchain_groq-0.3.7-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (0.3.75)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n","Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain-groq) (0.4.23)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain-groq) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain-groq) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain-groq) (6.0.2)\n","Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain-groq) (25.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain-groq) (3.0.0)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-groq) (3.11.3)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-groq) (1.0.0)\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-groq) (2.32.4)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-groq) (0.24.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-groq) (3.4.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-groq) (2.5.0)\n","Downloading groq-0.31.1-py3-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_groq-0.3.7-py3-none-any.whl (16 kB)\n","Installing collected packages: groq, langchain-groq\n","Successfully installed groq-0.31.1 langchain-groq-0.3.7\n"]}]},{"cell_type":"markdown","id":"327550d4","metadata":{"id":"327550d4"},"source":["## Imports"]},{"cell_type":"code","source":["import os\n","import getpass\n","\n","os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"GROQ API Key:\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jUfraHgVP5un","executionInfo":{"status":"ok","timestamp":1757425093239,"user_tz":0,"elapsed":10683,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"346a8c15-cc94-471f-aa88-d90a6d0a2dfa"},"id":"jUfraHgVP5un","execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":["GROQ API Key:\n","··········\n"]}]},{"cell_type":"code","execution_count":3,"id":"75febe51","metadata":{"id":"75febe51","executionInfo":{"status":"ok","timestamp":1757425131682,"user_tz":0,"elapsed":936,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["from langchain_groq import ChatGroq\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnableLambda"]},{"cell_type":"markdown","id":"9bc7aca5-1c4a-4cb0-bd28-d8a7636cc96d","metadata":{"id":"9bc7aca5-1c4a-4cb0-bd28-d8a7636cc96d"},"source":["---"]},{"cell_type":"markdown","id":"5c0e1244","metadata":{"id":"5c0e1244"},"source":["## Create a Model Instance"]},{"cell_type":"code","execution_count":4,"id":"c2c05c82","metadata":{"id":"c2c05c82","executionInfo":{"status":"ok","timestamp":1757425135792,"user_tz":0,"elapsed":425,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0)"]},{"cell_type":"markdown","id":"64d304e5-6bbe-4beb-ba92-fa208fb4c2f4","metadata":{"id":"64d304e5-6bbe-4beb-ba92-fa208fb4c2f4"},"source":["---"]},{"cell_type":"markdown","id":"b90f280c-cb9d-40d2-a6de-72d33308364e","metadata":{"id":"b90f280c-cb9d-40d2-a6de-72d33308364e"},"source":["## Using `RunnableLambda` to Create Custom Runnable Functions"]},{"cell_type":"markdown","id":"2c2519e1-99e4-4a1a-a624-a56b102f3a7f","metadata":{"id":"2c2519e1-99e4-4a1a-a624-a56b102f3a7f"},"source":["We have already seen that LangChain provides composable runnables in the forms of LLM instances, prompt templates, and output parsers. Another powerful tool that LangChain provides is the ability to convert arbitrary functions into runnables with `RunnableLambda`."]},{"cell_type":"code","execution_count":5,"id":"1be3fc6e-0ccd-4196-80a5-00be9a8b3ed5","metadata":{"id":"1be3fc6e-0ccd-4196-80a5-00be9a8b3ed5","executionInfo":{"status":"ok","timestamp":1757425145338,"user_tz":0,"elapsed":8,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["from langchain_core.runnables import RunnableLambda"]},{"cell_type":"markdown","id":"fd8086a8-a01f-4e4a-ad6b-2206e741ddd4","metadata":{"id":"fd8086a8-a01f-4e4a-ad6b-2206e741ddd4"},"source":["We will begin exploring custom runnable functions with a simply math function."]},{"cell_type":"code","execution_count":6,"id":"dd5425cd-8452-4742-96dd-73b31d299751","metadata":{"id":"dd5425cd-8452-4742-96dd-73b31d299751","executionInfo":{"status":"ok","timestamp":1757425163354,"user_tz":0,"elapsed":51,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["def double(x):\n","    return 2*x"]},{"cell_type":"markdown","id":"8565182a-d323-4466-b3d9-db49192acd0c","metadata":{"id":"8565182a-d323-4466-b3d9-db49192acd0c"},"source":["It should come as no surprise that this simple Python function does not have a LangChain runnable's `invoke` (or `batch` or `stream`) method."]},{"cell_type":"code","execution_count":7,"id":"d923ffb1-19d0-45d2-88b2-d0beaeabf1ed","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d923ffb1-19d0-45d2-88b2-d0beaeabf1ed","executionInfo":{"status":"ok","timestamp":1757425180879,"user_tz":0,"elapsed":12,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"f1459064-fe48-4a86-b371-d82cdc1acc8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["`double` is a Python function and does not have an `invoke` method.\n"]}],"source":["try:\n","    double.invoke(2)\n","except AttributeError:\n","    print('`double` is a Python function and does not have an `invoke` method.')"]},{"cell_type":"markdown","id":"6734fd4d-abfd-459f-b05d-9555a10837cb","metadata":{"id":"6734fd4d-abfd-459f-b05d-9555a10837cb"},"source":["However, we can easily convert it into a LangChain runnable by passing it into `RunnableLambda`."]},{"cell_type":"code","execution_count":8,"id":"658f876f-d02d-461c-b872-a69e818f0299","metadata":{"id":"658f876f-d02d-461c-b872-a69e818f0299","executionInfo":{"status":"ok","timestamp":1757425193896,"user_tz":0,"elapsed":6,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["runnable_double = RunnableLambda(double)"]},{"cell_type":"code","execution_count":9,"id":"87ebd04c-b23f-44c6-aa98-eae261002b3f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87ebd04c-b23f-44c6-aa98-eae261002b3f","executionInfo":{"status":"ok","timestamp":1757425198869,"user_tz":0,"elapsed":36,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"08493439-55c7-4f9c-db1d-e8442bf159b3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["12"]},"metadata":{},"execution_count":9}],"source":["runnable_double.invoke(6)"]},{"cell_type":"code","execution_count":10,"id":"09c8df39-eacd-429b-a980-5e2a9709782d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"09c8df39-eacd-429b-a980-5e2a9709782d","executionInfo":{"status":"ok","timestamp":1757425205306,"user_tz":0,"elapsed":28,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"21d9c5fe-e9ef-4bb6-a9b5-cb318521059f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[4, 8, 12, 16]"]},"metadata":{},"execution_count":10}],"source":["runnable_double.batch([2, 4, 6, 8])"]},{"cell_type":"markdown","id":"78e70712-178a-41e7-8b9b-9253caff962f","metadata":{"id":"78e70712-178a-41e7-8b9b-9253caff962f"},"source":["Like other runnables, custom function runnables like `runnable_double` can be composed into chains."]},{"cell_type":"code","execution_count":11,"id":"a5fcfc25-0818-4689-b2a7-117bf8adbd37","metadata":{"id":"a5fcfc25-0818-4689-b2a7-117bf8adbd37","executionInfo":{"status":"ok","timestamp":1757425319514,"user_tz":0,"elapsed":4,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["multiply_by_eight = runnable_double | runnable_double | runnable_double"]},{"cell_type":"code","execution_count":12,"id":"4147ffbd-10d8-415d-b551-f48ab7f51fb1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4147ffbd-10d8-415d-b551-f48ab7f51fb1","executionInfo":{"status":"ok","timestamp":1757425321478,"user_tz":0,"elapsed":8,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"fd0d0e0a-b17f-428d-e141-b269449a0858"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["88"]},"metadata":{},"execution_count":12}],"source":["multiply_by_eight.invoke(11)"]},{"cell_type":"markdown","id":"0c6bf3df-574a-45de-8e51-adc34a80b4ab","metadata":{"id":"0c6bf3df-574a-45de-8e51-adc34a80b4ab"},"source":["Your own creativity is the only limit as to how you might utilize custom functions in your chains, but for the remainder of this notebook we'll explore a couple common use cases for custom runnable functions in chains."]},{"cell_type":"markdown","id":"ff82e3be-4609-4958-b43b-c914cedec9cf","metadata":{"id":"ff82e3be-4609-4958-b43b-c914cedec9cf"},"source":["---"]},{"cell_type":"markdown","id":"b8f2d7b2-ddfb-4e66-b439-57a04974902f","metadata":{"id":"b8f2d7b2-ddfb-4e66-b439-57a04974902f"},"source":["## Data Management"]},{"cell_type":"markdown","id":"03742ff8-8fd7-465d-9279-e1b55bda569a","metadata":{"id":"03742ff8-8fd7-465d-9279-e1b55bda569a"},"source":["Whether for formatting, correction, or validation, you may wish to perform some work on data passing through your chains either before or after interacting with an LLM.\n","\n","As an example, suppose you are building a sentiment analysis application where user reviews are analyzed for their sentiment. User reviews can contain various inconsistencies like mixed capitalization, extra whitespace, and contractions. Normalizing this text before sending it to the LLM can improve the accuracy of the sentiment analysis.\n","\n","The following `normalize_text` function will normalize text by converting it to lowercase, expanding contractions, and removing extra whitespace."]},{"cell_type":"code","source":["!pip install contractions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJHnSS3fQPsk","executionInfo":{"status":"ok","timestamp":1757426038053,"user_tz":0,"elapsed":5022,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"f20b5a86-c332-4cda-eb3b-b3763a187949"},"id":"mJHnSS3fQPsk","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting contractions\n","  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n","Collecting textsearch>=0.0.21 (from contractions)\n","  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n","Collecting anyascii (from textsearch>=0.0.21->contractions)\n","  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n","Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n","  Downloading pyahocorasick-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n","Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n","Downloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyahocorasick-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n","Successfully installed anyascii-0.3.3 contractions-0.1.73 pyahocorasick-2.2.0 textsearch-0.0.24\n"]}]},{"cell_type":"code","execution_count":14,"id":"8498202f-8fdc-47cc-b9a7-42e62f2bd189","metadata":{"id":"8498202f-8fdc-47cc-b9a7-42e62f2bd189","executionInfo":{"status":"ok","timestamp":1757426075633,"user_tz":0,"elapsed":40,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["import re\n","import contractions # pip install contractions\n","\n","def normalize_text(text):\n","    # Convert text to lowercase\n","    text = text.lower()\n","\n","    # Expand contractions\n","    text = contractions.fix(text)\n","\n","    # Remove extra whitespace\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","\n","    return text"]},{"cell_type":"markdown","id":"974065b0-1873-40ae-be08-793fa4c9377a","metadata":{"id":"974065b0-1873-40ae-be08-793fa4c9377a"},"source":["---"]},{"cell_type":"markdown","id":"1908927e-7edd-43ed-ad53-90d55e3a2d7a","metadata":{"id":"1908927e-7edd-43ed-ad53-90d55e3a2d7a"},"source":["## Exercise: Create Runnable Function to Normalize Text"]},{"cell_type":"markdown","id":"f2a9e142-cbaf-4511-bf5b-b3b0600833ee","metadata":{"id":"f2a9e142-cbaf-4511-bf5b-b3b0600833ee"},"source":["Use what you've learned so far about creating runnable functions to create one out of the `normalize_text` function provided above.\n","\n","Upon successful implementation, you should be able to use it to batch process the following toy list of reviews.\n","\n","Feel free to check out the *Solution* below if you get stuck."]},{"cell_type":"code","execution_count":16,"id":"e8b77455-a259-4123-803b-0b246da74031","metadata":{"id":"e8b77455-a259-4123-803b-0b246da74031","executionInfo":{"status":"ok","timestamp":1757426229952,"user_tz":0,"elapsed":8,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["reviews = [\n","    \"I LOVE this product! It's absolutely amazing.   \",\n","    \"Not bad, but could be better. I've seen worse.\",\n","    \"Terrible experience... I'm never buying again!!\",\n","    \"Pretty good, isn't it? Will buy again!\",\n","    \"Excellent value for the money!!! Highly recommend.\"\n","]"]},{"cell_type":"markdown","id":"0df532f6-e639-4754-91a2-9da37302268c","metadata":{"id":"0df532f6-e639-4754-91a2-9da37302268c"},"source":["### Your Work Here"]},{"cell_type":"code","execution_count":null,"id":"a58513c8-9b00-47a9-8708-a367f25f4228","metadata":{"id":"a58513c8-9b00-47a9-8708-a367f25f4228"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"16bbd0d0-f7e1-43ed-83e3-b5dbdacb8a87","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"16bbd0d0-f7e1-43ed-83e3-b5dbdacb8a87"},"source":["### Solution"]},{"cell_type":"code","execution_count":17,"id":"1f668360-e36d-415a-a948-8c50e26a947f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1f668360-e36d-415a-a948-8c50e26a947f","executionInfo":{"status":"ok","timestamp":1757426234375,"user_tz":0,"elapsed":161,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"b3cf7a09-f517-4b1a-d056-094aeca0a97c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i love this product! it is absolutely amazing.',\n"," 'not bad, but could be better. i have seen worse.',\n"," 'terrible experience... i am never buying again!!',\n"," 'pretty good, is not it? will buy again!',\n"," 'excellent value for the money!!! highly recommend.']"]},"metadata":{},"execution_count":17}],"source":["RunnableLambda(normalize_text).batch(reviews)"]},{"cell_type":"markdown","id":"ba7c2bba-1309-445e-a377-0c831a4c165a","metadata":{"id":"ba7c2bba-1309-445e-a377-0c831a4c165a"},"source":["---"]},{"cell_type":"markdown","id":"97ddc32a-01bf-4e2e-96ac-f77f9d3bc256","metadata":{"id":"97ddc32a-01bf-4e2e-96ac-f77f9d3bc256"},"source":["## Formatting Text for Prompt Templates"]},{"cell_type":"markdown","id":"6edc9d93-0cb9-4465-91ba-b0b5ef24cad3","metadata":{"id":"6edc9d93-0cb9-4465-91ba-b0b5ef24cad3"},"source":["In the previous exercise you ended up with a list of normalized reviews like the following."]},{"cell_type":"code","execution_count":18,"id":"8868b24d-40df-446b-9b86-33f770716239","metadata":{"id":"8868b24d-40df-446b-9b86-33f770716239","executionInfo":{"status":"ok","timestamp":1757426237019,"user_tz":0,"elapsed":8,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["normalized_reviews = [\n","    'i love this product! it is absolutely amazing.',\n","    'not bad, but could be better. i have seen worse.',\n","    'terrible experience... i am never buying again!!',\n","    'pretty good, is not it? will buy again!',\n","    'excellent value for the money!!! highly recommend.'\n","]"]},{"cell_type":"markdown","id":"2bfd3110-7b3f-4329-97ff-87d3c23a56e0","metadata":{"id":"2bfd3110-7b3f-4329-97ff-87d3c23a56e0"},"source":["Let us assume now that we would like to pipe these normalized reviews in to a prompt template for sentiment analysis like the following `sentiment_template`."]},{"cell_type":"code","execution_count":19,"id":"5df2c06d-a289-415e-8026-f4cac697b1b6","metadata":{"id":"5df2c06d-a289-415e-8026-f4cac697b1b6","executionInfo":{"status":"ok","timestamp":1757426243260,"user_tz":0,"elapsed":41,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["sentiment_template = ChatPromptTemplate.from_template(\"\"\"In a single word, either 'positive' or 'negative', \\\n","provide the overall sentiment of the following piece of text: {text}\"\"\")"]},{"cell_type":"markdown","id":"8cff615d-c39f-47cc-b79d-0b5e1d5ec2dd","metadata":{"id":"8cff615d-c39f-47cc-b79d-0b5e1d5ec2dd"},"source":["We know from the previous notebook that to invoke the above template, we need to pass in a dictionary that contains keys for its placeholders (`{text}` in the above template), for example:"]},{"cell_type":"code","execution_count":20,"id":"ca532b43-40ba-4df9-ae52-294e32372858","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ca532b43-40ba-4df9-ae52-294e32372858","executionInfo":{"status":"ok","timestamp":1757426244920,"user_tz":0,"elapsed":25,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"f9feba60-9433-44dd-84ff-2572a6fd73e6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["ChatPromptValue(messages=[HumanMessage(content=\"In a single word, either 'positive' or 'negative', provide the overall sentiment of the following piece of text: i love this product! it is absolutely amazing.\", additional_kwargs={}, response_metadata={})])"]},"metadata":{},"execution_count":20}],"source":["sentiment_template.invoke({\"text\": 'i love this product! it is absolutely amazing.'})"]},{"cell_type":"markdown","id":"7203321c-f7f3-4d16-9353-9df777a02d27","metadata":{"id":"7203321c-f7f3-4d16-9353-9df777a02d27"},"source":["Therefore, in order to prepare the items in `normalized_review` for being piped into `sentiment_template`, we need to convert each line of text into a dictionary with the key `\"text\"` and the value the actual line of text.\n","\n","Let's create a runnable lambda to accomplish this. For this function we'll use an actual lambda function since the work we need to do is so minimal and define the runnable lambda straightaway."]},{"cell_type":"code","execution_count":21,"id":"a29aac6c-bb4d-479b-ba74-730a3bf0399f","metadata":{"id":"a29aac6c-bb4d-479b-ba74-730a3bf0399f","executionInfo":{"status":"ok","timestamp":1757426260563,"user_tz":0,"elapsed":30,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["prep_for_sentiment_template = RunnableLambda(lambda text: {\"text\": text})"]},{"cell_type":"markdown","id":"67c08427-59d9-40b1-8a97-b1dd18fa0856","metadata":{"id":"67c08427-59d9-40b1-8a97-b1dd18fa0856"},"source":["We can now use `prep_for_sentiment_template` to prep `normalized_reviews` for `sentiment_template`."]},{"cell_type":"code","execution_count":22,"id":"af47bec7-faae-439d-a872-c3e0d74cd30f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"af47bec7-faae-439d-a872-c3e0d74cd30f","executionInfo":{"status":"ok","timestamp":1757426265121,"user_tz":0,"elapsed":14,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"94ba6699-2637-498e-ed99-b9d5053f7e7c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'text': 'i love this product! it is absolutely amazing.'},\n"," {'text': 'not bad, but could be better. i have seen worse.'},\n"," {'text': 'terrible experience... i am never buying again!!'},\n"," {'text': 'pretty good, is not it? will buy again!'},\n"," {'text': 'excellent value for the money!!! highly recommend.'}]"]},"metadata":{},"execution_count":22}],"source":["prep_for_sentiment_template.batch(normalized_reviews)"]},{"cell_type":"markdown","id":"9d771328-a2d2-4a24-aee9-24d2bc305af3","metadata":{"id":"9d771328-a2d2-4a24-aee9-24d2bc305af3"},"source":["---"]},{"cell_type":"markdown","id":"eee11871-ef0c-4a37-8ced-791409ffa687","metadata":{"id":"eee11871-ef0c-4a37-8ced-791409ffa687"},"source":["## Exercise: Create a Sentiment Analysis Chain"]},{"cell_type":"markdown","id":"7e06ad31-5cb4-4889-a41a-4a65f8df05e5","metadata":{"id":"7e06ad31-5cb4-4889-a41a-4a65f8df05e5"},"source":["For this exercise, create a sentiment analysis chain that you can pass the original `reviews` list above into as a batch.\n","\n","Your chain should:\n","- Normalize the raw reviews.\n","- Prepare the normalized reviews for use in `sentiment_template` (defined above).\n","- Pipe the prepared normalized reviews through the `sentiment_template`.\n","- Pipe the prompt templates to `llm` (already defined above).\n","- Conclude by parsing the LLM outputs with an instance of `StrOutputParser`, which you will need to instantiate.\n","\n","Feel free to check out the solution below if you get stuck."]},{"cell_type":"markdown","id":"6b6f7036-dcc6-4eb0-88f9-8fb9f2869bc8","metadata":{"id":"6b6f7036-dcc6-4eb0-88f9-8fb9f2869bc8"},"source":["### Your Work"]},{"cell_type":"code","execution_count":null,"id":"e65f7deb-7b16-41f1-867e-e755f88c822e","metadata":{"id":"e65f7deb-7b16-41f1-867e-e755f88c822e"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"683e966d-42a7-46fd-805e-d0ea15cd09cf","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"683e966d-42a7-46fd-805e-d0ea15cd09cf"},"source":["### Solution"]},{"cell_type":"markdown","id":"0091a3c6-b025-4cd0-b53e-bf7474e625c4","metadata":{"id":"0091a3c6-b025-4cd0-b53e-bf7474e625c4"},"source":["The only component of the chain we haven't created yet is the output parser, so we create it here."]},{"cell_type":"code","execution_count":23,"id":"47a6af59-469c-45b2-8c2a-e3f2cb0bae33","metadata":{"id":"47a6af59-469c-45b2-8c2a-e3f2cb0bae33","executionInfo":{"status":"ok","timestamp":1757426279453,"user_tz":0,"elapsed":8,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["parser = StrOutputParser()"]},{"cell_type":"markdown","id":"d146bbd1-7898-48f0-8791-981ee092f865","metadata":{"id":"d146bbd1-7898-48f0-8791-981ee092f865"},"source":["With all the runnables created, we can compose our chain."]},{"cell_type":"code","execution_count":24,"id":"3ed50d95-b020-44f7-b374-1452ca47bec2","metadata":{"id":"3ed50d95-b020-44f7-b374-1452ca47bec2","executionInfo":{"status":"ok","timestamp":1757426311056,"user_tz":0,"elapsed":12,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["sentiment_chain = RunnableLambda(normalize_text) | prep_for_sentiment_template | sentiment_template | llm | parser"]},{"cell_type":"markdown","id":"16ff589e-4721-4661-b922-fb80fee0e8d3","metadata":{"id":"16ff589e-4721-4661-b922-fb80fee0e8d3"},"source":["Now we can batch our raw reviews through the chain."]},{"cell_type":"code","execution_count":25,"id":"721563ea-9dba-4b76-87ec-ed0f00055952","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"721563ea-9dba-4b76-87ec-ed0f00055952","executionInfo":{"status":"ok","timestamp":1757426313289,"user_tz":0,"elapsed":445,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"8a1fdf41-c044-4348-e2df-f0e5315070eb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Positive.', 'Negative.', 'Negative', 'Positive.', 'Positive.']"]},"metadata":{},"execution_count":25}],"source":["sentiment_chain.batch(reviews)"]},{"cell_type":"markdown","id":"b4865f24-5d8a-4185-a526-efed0fb4e518","metadata":{"id":"b4865f24-5d8a-4185-a526-efed0fb4e518"},"source":["---"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}