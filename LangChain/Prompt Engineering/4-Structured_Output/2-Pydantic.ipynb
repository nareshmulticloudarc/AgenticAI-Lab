{"cells":[{"cell_type":"markdown","id":"83ac4051-bf0b-4add-aafa-69b3ee443a71","metadata":{"id":"83ac4051-bf0b-4add-aafa-69b3ee443a71"},"source":["# Structured Output with Pydantic"]},{"cell_type":"markdown","id":"28013522","metadata":{"id":"28013522"},"source":["In this notebook you will drastically upgrade your ability to generate structured output through a combination of Pydantic classes and LangChain's `JsonOutputParser`."]},{"cell_type":"markdown","id":"69366671-11a4-4439-b6ad-cb89497ef5d4","metadata":{"id":"69366671-11a4-4439-b6ad-cb89497ef5d4"},"source":["---"]},{"cell_type":"markdown","id":"c08054f2","metadata":{"id":"c08054f2"},"source":["## Objectives"]},{"cell_type":"markdown","id":"a023bc7a-47b5-4508-957c-f3354c9fb363","metadata":{"id":"a023bc7a-47b5-4508-957c-f3354c9fb363"},"source":["By the time you complete this notebook you will:\n","\n","- Understand the limitations of our current approach to generating structured data.\n","- Learn to create class-driven schemas for structured data generation using Pydantic."]},{"cell_type":"markdown","id":"f4e9ea06-814f-43fd-9f59-ce67dfcb1bbb","metadata":{"id":"f4e9ea06-814f-43fd-9f59-ce67dfcb1bbb"},"source":["---"]},{"cell_type":"markdown","id":"327550d4","metadata":{"id":"327550d4"},"source":["## Imports"]},{"cell_type":"code","source":["!pip install groq langchain-groq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FRcBDIWNEEg_","executionInfo":{"status":"ok","timestamp":1757517123860,"user_tz":-330,"elapsed":19158,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"92e470a2-854c-4b45-b3ad-d9fa0bb6c828","collapsed":true},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting groq\n","  Downloading groq-0.31.1-py3-none-any.whl.metadata (16 kB)\n","Collecting langchain-groq\n","  Downloading langchain_groq-0.3.8-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (0.3.75)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n","Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.4.24)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (6.0.2)\n","Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (25.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.0.0)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.11.3)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.0.0)\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.32.4)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.24.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.4.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.5.0)\n","Downloading groq-0.31.1-py3-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_groq-0.3.8-py3-none-any.whl (16 kB)\n","Installing collected packages: groq, langchain-groq\n","Successfully installed groq-0.31.1 langchain-groq-0.3.8\n"]}],"id":"FRcBDIWNEEg_"},{"cell_type":"code","source":["import os\n","import getpass\n","\n","os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"GROQ API Key:\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qCEbkmakEHVG","executionInfo":{"status":"ok","timestamp":1757517126664,"user_tz":-330,"elapsed":2801,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"9925b697-b693-4430-b34a-767046167d54"},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":["GROQ API Key:\n","··········\n"]}],"id":"qCEbkmakEHVG"},{"cell_type":"code","execution_count":3,"metadata":{"id":"v3zlG4fZP1Tq","executionInfo":{"status":"ok","timestamp":1757517128327,"user_tz":-330,"elapsed":1662,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a1428561-88d1-47ce-c60c-a0621316c570"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n","\n","For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n","with: `from pydantic import BaseModel`\n","or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n","\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]}],"source":["from langchain_groq import ChatGroq\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n","from langchain_core.runnables import RunnableLambda\n","from langchain_core.pydantic_v1 import BaseModel, Field"],"id":"v3zlG4fZP1Tq"},{"cell_type":"markdown","id":"9bc7aca5-1c4a-4cb0-bd28-d8a7636cc96d","metadata":{"id":"9bc7aca5-1c4a-4cb0-bd28-d8a7636cc96d"},"source":["---"]},{"cell_type":"markdown","id":"5c0e1244","metadata":{"id":"5c0e1244"},"source":["## Create a Model Instance"]},{"cell_type":"code","source":["llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0)"],"metadata":{"id":"fC2AoQ9fENfw","executionInfo":{"status":"ok","timestamp":1757517129012,"user_tz":-330,"elapsed":678,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"execution_count":4,"outputs":[],"id":"fC2AoQ9fENfw"},{"cell_type":"markdown","id":"b90f280c-cb9d-40d2-a6de-72d33308364e","metadata":{"id":"b90f280c-cb9d-40d2-a6de-72d33308364e"},"source":["## Limitations of Our Current Structured Data Approach"]},{"cell_type":"markdown","id":"58dec2db-ee68-4588-b3f2-bc2f94a4bc3b","metadata":{"id":"58dec2db-ee68-4588-b3f2-bc2f94a4bc3b"},"source":["Your implementation might have been slightly different, but in the solution to the previous notebook's exercise we had some success with the following prompt template to generate a JSON object containing book details."]},{"cell_type":"code","execution_count":5,"id":"14cb1a4d-6212-41dd-b61f-83b96cac986b","metadata":{"id":"14cb1a4d-6212-41dd-b61f-83b96cac986b","executionInfo":{"status":"ok","timestamp":1757517142390,"user_tz":-330,"elapsed":4,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["book_template = ChatPromptTemplate.from_template('''\\\n","Make a JSON object representing the details of the following book: {book_title}. \\\n","It should have fields for:\n","- The title of the book.\n","- The author of the book.\n","- The year the book was originally published.\n","\n","Only return the JSON. Never return non-JSON text including backtack wrappers around the JSON.''')"]},{"cell_type":"markdown","id":"52bba5db-7572-45d1-859e-efef66d58353","metadata":{"id":"52bba5db-7572-45d1-859e-efef66d58353"},"source":["Using this template, our solution implementation generated the following list of book details:"]},{"cell_type":"markdown","id":"742281bb-feca-4875-b051-fc53978f983f","metadata":{"id":"742281bb-feca-4875-b051-fc53978f983f"},"source":["```python\n","[{'title': 'Dune', 'author': 'Frank Herbert', 'year_of_publication': 1965},\n"," {'title': 'Neuromancer', 'author': 'William Gibson', 'year': 1984},\n"," {'title': 'Snow Crash', 'author': 'Neal Stephenson', 'yearPublished': '1992'},\n"," {'title': 'The Left Hand of Darkness',\n","  'author': None,\n","  'publication_year': None},\n"," {'title': 'Foundation', 'author': 'Isaac Asimov', 'year': '1951'}]\n"," ```"]},{"cell_type":"markdown","id":"e1e8ae50-6f43-43c5-b4ee-c1ad05dc23b1","metadata":{"id":"e1e8ae50-6f43-43c5-b4ee-c1ad05dc23b1"},"source":["The result was well-formatted, but looking more carefully at it, we can see it has some issues:\n","\n","- The key names are not consistent for all values, for example `'year_of_publication'`, `'year'`, and `'yearPublished'`.\n","- The year has been generated at times as a string (`'1992'`), at times as an int (`1984`), and at times as a NoneType.\n","\n","At this point in the workshop, knowing what you already do, you're probably already full of ideas about how to address each of these. Perhaps the following ideas come to mind:\n","\n","- Be more specific in our prompt about the names of the keys, the types of the values, and what to do when the LLM can't generate data for a field.\n","- Try including a system message to more strongly reinforce how we want the LLM to generate responses.\n","- Provide few-shot examples to help the model understand all the specifics of what it should and shouldn't do.\n","\n","If you're thinking along these lines, that's really fantastic, and you're correct about approaching the problem this way.\n","\n","But let's consider some of the ways that our task might get even more complicated:\n","\n","- What if we wanted to templatize more of the prompt, for example, which fields to include?\n","- What if our data structure gets far more complicated?\n","- Since we are generating data, what if we wanted to capture a definition of our data type for use elsewhere?\n","\n","Again, knowing what you already know, you can likely think of viable ways to accomplish each of these, though it's easy to imagine it getting rather complicated quick. Luckily for us, LangChain ships with a variety of tools to help us accomplish generating structured data, and using them will greatly simplify our application code and allow us to perform more complicated structured data generation tasks more easily."]},{"cell_type":"markdown","id":"43a49357-3ed8-4faa-8df1-071a6ffb2d72","metadata":{"id":"43a49357-3ed8-4faa-8df1-071a6ffb2d72"},"source":["---"]},{"cell_type":"markdown","id":"59a7f221-5b2b-4e28-bf59-6489995394d5","metadata":{"id":"59a7f221-5b2b-4e28-bf59-6489995394d5"},"source":["## Structured Data as a Class"]},{"cell_type":"markdown","id":"b1f49b25-498d-493f-96db-6b5e4564f689","metadata":{"id":"b1f49b25-498d-493f-96db-6b5e4564f689"},"source":["Even before we get to LangChain-specific tools to help us generate structured data, let's take a step back and think about how we might articulate a data structure in Python if we weren't working in the context of LLMs. One very sensible approach would be to create a Python class.\n","\n","Here we define a `Book` class that captures what we hoped to describe in our prompt template above."]},{"cell_type":"code","execution_count":null,"id":"a84071c1-82b7-4efe-9da3-29bb04fe4e79","metadata":{"id":"a84071c1-82b7-4efe-9da3-29bb04fe4e79"},"outputs":[],"source":["class Book:\n","    \"\"\"Information about a book.\"\"\"\n","\n","    def __init__(self, title, author, year_of_publication):\n","        self.title = title\n","        self.author = author\n","        self.year_of_publication = year_of_publication"]},{"cell_type":"markdown","id":"37c2900b-a797-42bf-b141-73ed054fb2be","metadata":{"id":"37c2900b-a797-42bf-b141-73ed054fb2be"},"source":["However, there are some details we discussed above about our structured data that this class does not yet capture, like the type of the value for each field. Also, unlike our actual prompt template, there is no description, aside from its name, about what each field ought to contain.\n","\n","Let's improve on this slightly but rewriting the class to include Python type hints, and some comments articulating the intended value of each field."]},{"cell_type":"code","execution_count":null,"id":"a62ea41a-07cc-491c-aa15-387e49fe8caf","metadata":{"id":"a62ea41a-07cc-491c-aa15-387e49fe8caf"},"outputs":[],"source":["class Book:\n","    \"\"\"Information about a book.\"\"\"\n","\n","    def __init__(self, title: str, author: str, year_of_publication: int):\n","        self.title: str = title  # The title of the book\n","        self.author: str = author  # The author of the book\n","        self.year_of_publication: int = year_of_publication  # The year the book was published"]},{"cell_type":"markdown","id":"3c9745ff-d9e2-4316-ac24-c3b6d3703c27","metadata":{"id":"3c9745ff-d9e2-4316-ac24-c3b6d3703c27"},"source":["It's still missing aspects like default values and data validation, but for the most part, if we had a way to convey the infomation contained in the above class, including its comments, in a prompt, we might be in pretty good shape."]},{"cell_type":"markdown","id":"0b41b487-913a-41b7-81ea-7ab5e920707d","metadata":{"id":"0b41b487-913a-41b7-81ea-7ab5e920707d"},"source":["---"]},{"cell_type":"markdown","id":"b37b0661-0764-45a0-876e-77adaf3dd5f3","metadata":{"id":"b37b0661-0764-45a0-876e-77adaf3dd5f3"},"source":["## Pydantic"]},{"cell_type":"markdown","id":"b65dbfee-c28a-449d-b99b-d59beabe1f59","metadata":{"id":"b65dbfee-c28a-449d-b99b-d59beabe1f59"},"source":["In fact, LangChain provides us with exactly what we need to convey the information contained in classes to prompts. In doing so we have a powerful tool that enables us to articulate the structure of the data we want generated in a class, and then let LangChain do some of the more tedious work of conveying the information we capture in the class to a prompt.\n","\n","In order to do this however, we need to use Pydantic classes instead of vanilla Python classes.\n","\n","If you're unfamiliar, [Pydantic](https://docs.pydantic.dev/latest/) is \"the most widely used data validation library for Python.\" If you're not using Pydantic in your object-oriented Python code, there's a good chance you'll enjoy learning how to use it.\n","\n","For our purposes, we are only going to be using Pydantic to construct straightforward classes so that LangChain can then work with our class definitions to create prompts that will assist us in generating structured data.\n","\n","The relevant Pydantic functionality has been integrated into LangChain, so to begin working with Pydantic classes, we need to import the following."]},{"cell_type":"code","execution_count":6,"id":"30a5b14b-c04c-4280-a3cf-65a69ecebd73","metadata":{"id":"30a5b14b-c04c-4280-a3cf-65a69ecebd73","executionInfo":{"status":"ok","timestamp":1757517546346,"user_tz":-330,"elapsed":10,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["from langchain_core.pydantic_v1 import BaseModel, Field"]},{"cell_type":"markdown","id":"8778ed99-349e-4a30-af69-7ee8b77964cc","metadata":{"id":"8778ed99-349e-4a30-af69-7ee8b77964cc"},"source":["Having imported `BaseModel` and `Field` we are now able to rewrite our `Book` class using Pydantic as follows."]},{"cell_type":"code","execution_count":7,"id":"9f2eba61-c9be-47b1-a903-4c030fcb58e0","metadata":{"id":"9f2eba61-c9be-47b1-a903-4c030fcb58e0","executionInfo":{"status":"ok","timestamp":1757517564173,"user_tz":-330,"elapsed":13,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["class Book(BaseModel):\n","    \"\"\"Information about a book.\"\"\"\n","\n","    title: str = Field(description=\"The title of the book\")\n","    author: str = Field(description=\"The author of the book\")\n","    year_of_publication: str = Field(description=\"The year the book was published\")"]},{"cell_type":"markdown","id":"f9c352ad-1185-46ec-b772-f1a59cc66b75","metadata":{"id":"f9c352ad-1185-46ec-b772-f1a59cc66b75"},"source":["As you can see, when we want to construct a Pydantic class, we create a class that inherits from `BaseModel` as we're doing above.\n","\n","Rather than creating an `__init__` function, we can supply the class's fields at the top level of the class definition by defining them with `Field`, which, as a convenience, allows us provide a `desciption` argument about the intended use of the field."]},{"cell_type":"markdown","id":"b511bfa5-175e-4947-9e3f-ab283ce68b0f","metadata":{"id":"b511bfa5-175e-4947-9e3f-ab283ce68b0f"},"source":["---"]},{"cell_type":"markdown","id":"ca9d9dd7-fb35-42c9-b7f4-32dd66e96155","metadata":{"id":"ca9d9dd7-fb35-42c9-b7f4-32dd66e96155"},"source":["## From Class to Formatting Instructions"]},{"cell_type":"markdown","id":"c88d5944-01f5-483c-b344-cd16d9755e59","metadata":{"id":"c88d5944-01f5-483c-b344-cd16d9755e59"},"source":["In order to take the structure defined in our Pydantic `Book` class and generate a JSON object, we need a prompt to provide the model. LangChain's `JsonOutputParser` will provide us with just that.\n","\n","First we'll import the `JsonOutputParser` class."]},{"cell_type":"code","execution_count":8,"id":"0104f0ad-ea9d-48a2-96a6-d3bd69baf424","metadata":{"id":"0104f0ad-ea9d-48a2-96a6-d3bd69baf424","executionInfo":{"status":"ok","timestamp":1757517602511,"user_tz":-330,"elapsed":1,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["from langchain_core.output_parsers import JsonOutputParser"]},{"cell_type":"markdown","id":"6aaf0580-220a-45a2-9e92-adda2a2ea596","metadata":{"id":"6aaf0580-220a-45a2-9e92-adda2a2ea596"},"source":["Just like with the `StrOutputParser` and `SimpleJsonOutputParser` parsers that we've used previously, we need to create an instance of the parser to use in our chain.\n","\n","Different from the parsers we've worked with earlier, however, we can provide `JsonOutputParser` with an argument `pydantic_object` and provide a Pydantic object expressing how we want the JSON to be parsed. Here we'll pass in our Pydantic `Book`."]},{"cell_type":"code","execution_count":9,"id":"04a4bbb5-ed42-4d97-8b87-81c5f14fb755","metadata":{"id":"04a4bbb5-ed42-4d97-8b87-81c5f14fb755","executionInfo":{"status":"ok","timestamp":1757517636781,"user_tz":-330,"elapsed":2,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["parser = JsonOutputParser(pydantic_object=Book)"]},{"cell_type":"markdown","id":"68200902-0c2f-4ff3-8a9f-64c40f3cda50","metadata":{"id":"68200902-0c2f-4ff3-8a9f-64c40f3cda50"},"source":["Instances of `JsonOutputParser` contain a `get_format_instructions` method which create explicit instructions for formatting the JSON based on the provided Pydantic object."]},{"cell_type":"code","execution_count":10,"id":"84c3909c-8273-4a88-a961-68cb8cf11d03","metadata":{"id":"84c3909c-8273-4a88-a961-68cb8cf11d03","executionInfo":{"status":"ok","timestamp":1757517661132,"user_tz":-330,"elapsed":3,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["format_instructions = parser.get_format_instructions()"]},{"cell_type":"code","execution_count":11,"id":"2a320644-97ee-480f-adda-f2b7a29555d3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2a320644-97ee-480f-adda-f2b7a29555d3","executionInfo":{"status":"ok","timestamp":1757517664884,"user_tz":-330,"elapsed":11,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"413a88ca-440c-4fd9-d0e2-d491390e7dd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["The output should be formatted as a JSON instance that conforms to the JSON schema below.\n","\n","As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n","the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n","\n","Here is the output schema:\n","```\n","{\"description\": \"Information about a book.\", \"properties\": {\"title\": {\"title\": \"Title\", \"description\": \"The title of the book\", \"type\": \"string\"}, \"author\": {\"title\": \"Author\", \"description\": \"The author of the book\", \"type\": \"string\"}, \"year_of_publication\": {\"title\": \"Year Of Publication\", \"description\": \"The year the book was published\", \"type\": \"string\"}}, \"required\": [\"title\", \"author\", \"year_of_publication\"]}\n","```\n"]}],"source":["print(format_instructions)"]},{"cell_type":"markdown","id":"98c7b877-ba45-46f0-836b-cdb5ef49dfb4","metadata":{"id":"98c7b877-ba45-46f0-836b-cdb5ef49dfb4"},"source":["This is a really fantastic convenience to have the parser generate these detailed formatting instructions for us."]},{"cell_type":"markdown","id":"ef771ea0-c1f2-4cb9-b3d7-400329a40d8f","metadata":{"id":"ef771ea0-c1f2-4cb9-b3d7-400329a40d8f"},"source":["---"]},{"cell_type":"markdown","id":"251cc5e4-fa8a-45e3-8a7a-64cdc5a3a4ba","metadata":{"id":"251cc5e4-fa8a-45e3-8a7a-64cdc5a3a4ba"},"source":["## The Importance of Docstrings and Field Descriptions"]},{"cell_type":"markdown","id":"642467bc-9d06-44e7-b429-9aa0c8576439","metadata":{"id":"642467bc-9d06-44e7-b429-9aa0c8576439"},"source":["In the `format_instructions` above you'll notice several `\"description\"` fields. The top level `\"description\"` field states `\"\"Information about a book.\"\"`, the `\"title\"` `\"description\"` field states `\"The title of the book\"`. If we look again at our Pydantic class definition..."]},{"cell_type":"code","execution_count":null,"id":"f031ea5d-4bb4-41e4-82eb-f746649f0afb","metadata":{"id":"f031ea5d-4bb4-41e4-82eb-f746649f0afb"},"outputs":[],"source":["class Book(BaseModel):\n","    \"\"\"Information about a book.\"\"\"\n","\n","    title: str = Field(description=\"The title of the book\")\n","    author: str = Field(description=\"The author of the book\")\n","    year_of_publication: str = Field(description=\"The year the book was published\")"]},{"cell_type":"markdown","id":"d9066aaf-18c9-457e-948a-e49806124291","metadata":{"id":"d9066aaf-18c9-457e-948a-e49806124291"},"source":["...you'll see that these descriptions were created from the class's docstring (for the top level description) and for each of the passed in `description` values (for each of the fields).\n","\n","These texts are critical for conveying our intent to the LLM. When creating Pydantic classes to be used as formatting tools with LLMs, always take care to provide a meaningful docstring for the entire class, as well as good descriptions for each of its fields."]},{"cell_type":"markdown","id":"4cfb9821-d64d-46db-9e7b-5137b96d3251","metadata":{"id":"4cfb9821-d64d-46db-9e7b-5137b96d3251"},"source":["---"]},{"cell_type":"markdown","id":"df75789b-6ebc-4501-bbc8-11dda90da907","metadata":{"id":"df75789b-6ebc-4501-bbc8-11dda90da907"},"source":["## Using Formatting Instructions in Prompts"]},{"cell_type":"markdown","id":"586acc56-a481-4576-b890-a8a883b2e4c6","metadata":{"id":"586acc56-a481-4576-b890-a8a883b2e4c6"},"source":["Let's leverage the formatting instructions created by `JsonOutputParser` based on the Pydantic `Book` class in a prompt. While we are at it, we might as well also supply a system message to support our intended goal."]},{"cell_type":"code","execution_count":12,"id":"a08db68e-38b6-40d2-abe6-c1f056ac3d54","metadata":{"id":"a08db68e-38b6-40d2-abe6-c1f056ac3d54","executionInfo":{"status":"ok","timestamp":1757517821479,"user_tz":-330,"elapsed":10,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["template = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are an AI that generates JSON and ONLY JSON according to the instructions provided to you.\"),\n","    (\"human\", (\n","        \"Generate JSON about the user input according to the provided format instructions.\\n\" +\n","        \"Input: {input}\\n\" +\n","        \"Format instructions {format_instructions}\")\n","    )\n","])"]},{"cell_type":"markdown","id":"6f63b188-8608-48db-94d1-5ef5ec0102d6","metadata":{"id":"6f63b188-8608-48db-94d1-5ef5ec0102d6"},"source":["Next we'll create our chain."]},{"cell_type":"code","execution_count":13,"id":"64f94046-6e52-4abc-ae57-d424bc8a2a11","metadata":{"id":"64f94046-6e52-4abc-ae57-d424bc8a2a11","executionInfo":{"status":"ok","timestamp":1757517829407,"user_tz":-330,"elapsed":4,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["chain = template | llm | parser # Created above with `parser = JsonOutputParser(pydantic_object=Book)`"]},{"cell_type":"markdown","id":"9c35f683-f6b6-452d-9ea6-4b66783864a5","metadata":{"id":"9c35f683-f6b6-452d-9ea6-4b66783864a5"},"source":["When we invoke this template, we'll need to provide an `input`, which in this case should be a book title, as well as `format_instructions`, which we have already obtained from `parser.format_instructions()`."]},{"cell_type":"code","execution_count":14,"id":"e7c2197c-41ae-4371-acda-fd61c532ef4d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7c2197c-41ae-4371-acda-fd61c532ef4d","executionInfo":{"status":"ok","timestamp":1757517845029,"user_tz":-330,"elapsed":607,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"1fa7ed73-50f8-44b7-aad6-84dac500c1d3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'title': 'East of Eden',\n"," 'author': 'John Steinbeck',\n"," 'year_of_publication': '1952'}"]},"metadata":{},"execution_count":14}],"source":["chain.invoke({\n","    \"input\": \"East of Eden\",\n","    \"format_instructions\": format_instructions\n","})"]},{"cell_type":"markdown","id":"191a1c18-816f-4b7e-b593-c056905001e4","metadata":{"id":"191a1c18-816f-4b7e-b593-c056905001e4"},"source":["Since we are going to want to provide different `input` values, but retain the same `format_instructions`, we can partially apply our existing `format_instructions` to the prompt template using the template's `.partial` method."]},{"cell_type":"code","execution_count":15,"id":"e9b85e3b-ddc8-4459-96da-f80f8ba1bc6d","metadata":{"id":"e9b85e3b-ddc8-4459-96da-f80f8ba1bc6d","executionInfo":{"status":"ok","timestamp":1757517864493,"user_tz":-330,"elapsed":43,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["chain = template.partial(format_instructions=format_instructions) | llm | parser # Created above with `parser = JsonOutputParser(pydantic_object=Book)`"]},{"cell_type":"markdown","id":"65dbf8d9-bd08-4999-aaf8-f2663f823094","metadata":{"id":"65dbf8d9-bd08-4999-aaf8-f2663f823094"},"source":["Let's try our new chain with a batch of books."]},{"cell_type":"code","execution_count":16,"id":"abed9eea-090b-4f9c-a727-9220c3448232","metadata":{"id":"abed9eea-090b-4f9c-a727-9220c3448232","executionInfo":{"status":"ok","timestamp":1757517867889,"user_tz":-330,"elapsed":3,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["book_titles = [\"Dune\", \"Neuromancer\", \"Snow Crash\", \"The Left Hand of Darkness\", \"Foundation\"]"]},{"cell_type":"code","execution_count":17,"id":"bb70ce41-eeb0-4b8c-ace8-2f105da46c95","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bb70ce41-eeb0-4b8c-ace8-2f105da46c95","executionInfo":{"status":"ok","timestamp":1757517872290,"user_tz":-330,"elapsed":441,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"16b1d120-27d6-4176-fd56-b99ca2b31ac0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'title': 'Dune', 'author': 'Frank Herbert', 'year_of_publication': '1965'},\n"," {'title': 'Neuromancer',\n","  'author': 'William Gibson',\n","  'year_of_publication': '1984'},\n"," {'title': 'Snow Crash',\n","  'author': 'Neal Stephenson',\n","  'year_of_publication': '1992'},\n"," {'title': 'The Left Hand of Darkness',\n","  'author': 'Ursula K. Le Guin',\n","  'year_of_publication': '1969'},\n"," {'title': 'Foundation',\n","  'author': 'Isaac Asimov',\n","  'year_of_publication': '1951'}]"]},"metadata":{},"execution_count":17}],"source":["chain.batch(book_titles)"]},{"cell_type":"markdown","id":"2016419b-d66b-4d40-b598-3caf093760d6","metadata":{"id":"2016419b-d66b-4d40-b598-3caf093760d6"},"source":["Comparing this to the output from the previous notebook (see immediately below), you can see our results are more consistent and better."]},{"cell_type":"markdown","id":"648d3f03-f0c6-42fb-9de0-f7e554bc537b","metadata":{"id":"648d3f03-f0c6-42fb-9de0-f7e554bc537b"},"source":["```python\n","[{'title': 'Dune', 'author': 'Frank Herbert', 'year_of_publication': 1965},\n"," {'title': 'Neuromancer', 'author': 'William Gibson', 'year': 1984},\n"," {'title': 'Snow Crash', 'author': 'Neal Stephenson', 'yearPublished': '1992'},\n"," {'title': 'The Left Hand of Darkness',\n","  'author': None,\n","  'publication_year': None},\n"," {'title': 'Foundation', 'author': 'Isaac Asimov', 'year': '1951'}]\n"," ```"]},{"cell_type":"markdown","id":"c93cc6b9-91e8-4a35-a51a-35245bdd0cce","metadata":{"id":"c93cc6b9-91e8-4a35-a51a-35245bdd0cce"},"source":["---"]},{"cell_type":"markdown","id":"daa99986-c8fb-450d-9e5a-ef2e09625211","metadata":{"id":"daa99986-c8fb-450d-9e5a-ef2e09625211"},"source":["## Using with_structured_output"]},{"cell_type":"markdown","id":"16e31fd0-5107-412e-9fc9-1decfc8f5708","metadata":{"id":"16e31fd0-5107-412e-9fc9-1decfc8f5708"},"source":["As an alternative, and improved way to generate structured output, many LLMs now support the `with_structured_output` method, which allows us to replace the following..."]},{"cell_type":"markdown","id":"c451fa44-e6d5-4390-8543-3c4a10e390f9","metadata":{"id":"c451fa44-e6d5-4390-8543-3c4a10e390f9"},"source":["```python\n","template = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are an AI that generates JSON and only JSON according to the instructions provided to you.\"),\n","    (\"human\", (\n","        \"Generate JSON about the user input according to the provided format instructions.\\n\" +\n","        \"Input: {input}\\n\" +\n","        \"Format instructions {format_instructions}\")\n","    )\n","])\n","\n","chain = template.partial(format_instructions=format_instructions) | llm | JsonOutputParser(pydantic_object=Book)\n","```"]},{"cell_type":"markdown","id":"b01ff72c-1805-4cdb-961f-1c2c92e631f6","metadata":{"id":"b01ff72c-1805-4cdb-961f-1c2c92e631f6"},"source":["... with:"]},{"cell_type":"markdown","id":"c5bed911-c5ed-46c3-8da0-0dd3320c4ffc","metadata":{"id":"c5bed911-c5ed-46c3-8da0-0dd3320c4ffc"},"source":["```python\n","llm_structured = llm.with_structured_output(Book)\n","```"]},{"cell_type":"markdown","id":"c3cf92b1-4de7-485b-ba2a-e85707ffbffe","metadata":{"id":"c3cf92b1-4de7-485b-ba2a-e85707ffbffe"},"source":["In the example just shown, `llm_structured` can be invoked, batched, or streamed just like `chain`, but the syntax is much more concise.\n","\n"]},{"cell_type":"markdown","id":"f6339367-609a-4344-bb73-e185de96b799","metadata":{"id":"f6339367-609a-4344-bb73-e185de96b799"},"source":["---"]},{"cell_type":"markdown","id":"fb9b087c-660b-45e6-807e-34e7652378f3","metadata":{"id":"fb9b087c-660b-45e6-807e-34e7652378f3"},"source":["## Exercise: Leverage Pydantic for Structured Data Generation"]},{"cell_type":"markdown","id":"8fa06ed6-ddb8-43f0-859b-ad1ff29726f4","metadata":{"id":"8fa06ed6-ddb8-43f0-859b-ad1ff29726f4"},"source":["For this exercise you are going to generate a batch of structured data for the following cites."]},{"cell_type":"code","execution_count":18,"id":"194620bf-e75b-45d7-ab13-7ce2dbef441e","metadata":{"id":"194620bf-e75b-45d7-ab13-7ce2dbef441e","executionInfo":{"status":"ok","timestamp":1757517967408,"user_tz":-330,"elapsed":1,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["city_names = ['Tokyo', 'Busan', 'Cairo', 'Perth']"]},{"cell_type":"markdown","id":"d2b68659-0c7c-440a-924a-e94738dc0e2b","metadata":{"id":"d2b68659-0c7c-440a-924a-e94738dc0e2b"},"source":["For each of these cities you should create a JSON blob that contains information about the city, including:\n","- The name of the city.\n","- The country that the city is located within.\n","- Whether or not the city is the capital city of the country it is located in.\n","- The population of the city.\n","\n","Feel free to check out the Solution below if you get stuck."]},{"cell_type":"markdown","id":"3e91e42b-bca3-433e-a9a8-d65b0af492f5","metadata":{"id":"3e91e42b-bca3-433e-a9a8-d65b0af492f5"},"source":["### Your Work Here"]},{"cell_type":"code","execution_count":null,"id":"98b43404-3d7e-4808-a8c7-e34f071540af","metadata":{"id":"98b43404-3d7e-4808-a8c7-e34f071540af"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"b365184a-e047-4ba0-b11f-768a49dc683c","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"b365184a-e047-4ba0-b11f-768a49dc683c"},"source":["### Solution"]},{"cell_type":"code","execution_count":21,"id":"9eaaed0d-f374-484b-802a-feea6cdc701c","metadata":{"id":"9eaaed0d-f374-484b-802a-feea6cdc701c","executionInfo":{"status":"ok","timestamp":1757518011560,"user_tz":-330,"elapsed":4,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["class City(BaseModel):\n","    \"\"\"Information about a city.\"\"\"\n","\n","    name: str = Field(description=\"The name of the city\")\n","    country: str = Field(description=\"The the country the city is located in\")\n","    capital: bool = Field(description=\"Is the city the capital of the country it is located in\")\n","    population: int = Field(description=\"The population of the city\")"]},{"cell_type":"code","execution_count":19,"id":"c00e50be-8893-4946-bb56-4ac09be83833","metadata":{"id":"c00e50be-8893-4946-bb56-4ac09be83833","executionInfo":{"status":"ok","timestamp":1757518000405,"user_tz":-330,"elapsed":4,"user":{"displayName":"naveen b","userId":"07342808041236324682"}}},"outputs":[],"source":["template = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are an AI that generates JSON and only JSON according to the instructions provided to you.\"),\n","    (\"human\", (\n","        \"Generate JSON about the user input according to the provided format instructions.\\n\" +\n","        \"Input: {input}\\n\" +\n","        \"Format instructions {format_instructions}\")\n","    )\n","])"]},{"cell_type":"code","execution_count":20,"id":"be9e3dd7-de83-4a60-8cb4-baeaf4cd0bd5","metadata":{"id":"be9e3dd7-de83-4a60-8cb4-baeaf4cd0bd5","executionInfo":{"status":"error","timestamp":1757518001939,"user_tz":-330,"elapsed":9,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"46477830-0991-49e9-c95a-ed6f11298237"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'City' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-63455571.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJsonOutputParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydantic_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'City' is not defined"]}],"source":["parser = JsonOutputParser(pydantic_object=City)"]},{"cell_type":"code","execution_count":null,"id":"899952ac-3bba-45d2-a1d6-7b7cb4425bfa","metadata":{"id":"899952ac-3bba-45d2-a1d6-7b7cb4425bfa"},"outputs":[],"source":["template_with_format_instructions = template.partial(format_instructions=parser.get_format_instructions())"]},{"cell_type":"code","execution_count":null,"id":"1c3dca4e-62ed-4dab-98ff-1b8c2589b005","metadata":{"id":"1c3dca4e-62ed-4dab-98ff-1b8c2589b005"},"outputs":[],"source":["chain = template_with_format_instructions | llm | parser"]},{"cell_type":"code","execution_count":null,"id":"4497989d-5f2e-46eb-bf64-a695467ab785","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4497989d-5f2e-46eb-bf64-a695467ab785","executionInfo":{"status":"ok","timestamp":1757267885583,"user_tz":-330,"elapsed":616,"user":{"displayName":"naveen b","userId":"07342808041236324682"}},"outputId":"f2cd04c7-ef87-41c5-fbf4-389b2a751b6a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'name': 'Tokyo',\n","  'country': 'Japan',\n","  'capital': True,\n","  'population': 13969100},\n"," {'name': 'Busan',\n","  'country': 'South Korea',\n","  'capital': False,\n","  'population': 3420000},\n"," {'name': 'Cairo',\n","  'country': 'Egypt',\n","  'capital': True,\n","  'population': 10230000},\n"," {'name': 'Perth',\n","  'country': 'Australia',\n","  'capital': False,\n","  'population': 2045553}]"]},"metadata":{},"execution_count":27}],"source":["chain.batch(city_names)"]},{"cell_type":"markdown","id":"eee83cf7-9811-42bc-893a-cb33ae2d8ecf","metadata":{"id":"eee83cf7-9811-42bc-893a-cb33ae2d8ecf"},"source":["---"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}